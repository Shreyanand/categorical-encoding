{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Encoding\n",
    "\n",
    "* In this noebook, we experiment with different encdoers, models, and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:53:00.295255Z",
     "start_time": "2020-05-22T20:53:00.127764Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install fasttext dirty_cat category_encoders\n",
    "# !pip install lightgbm xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:49:29.490628Z",
     "start_time": "2020-05-21T00:49:29.486064Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from get_data import dataloader\n",
    "from column_encoder import ColumnEncoder #This is where the magic happens\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "import get_data\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "import category_encoders as ce\n",
    "#from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "# kc_train = dataloader('data/kaggle_cat_train.csv', \"kaggle_cat\")\n",
    "# kc_train.get_input_target()\n",
    "# kc_test = dataloader('data/kaggle_cat_train.csv', \"kaggle_cat\")\n",
    "# kc_test.get_input_target()\n",
    "# nominal = ['nom_'+str(i) for i in range(0,10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:49:30.096238Z",
     "start_time": "2020-05-21T00:49:29.994897Z"
    }
   },
   "outputs": [],
   "source": [
    "insights = dataloader('data/Insights/insights.csv', \"insights\")\n",
    "insights.get_input_target()\n",
    "X_col = insights.X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:49:30.957130Z",
     "start_time": "2020-05-21T00:49:30.904233Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_train_split(X, y, test_size=0.33, random_state=1):\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    sss.get_n_splits(X, y)\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = test_train_split(insights.X, insights.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:49:34.338279Z",
     "start_time": "2020-05-21T00:49:34.335556Z"
    }
   },
   "outputs": [],
   "source": [
    "# sample_X_train = X_train[:2000]\n",
    "# sample_y_train = y_train[:2000]\n",
    "# sample_X_test = X_test[:200]\n",
    "# sample_y_test = y_test[:200]\n",
    "\n",
    "sample_X_train = X_train\n",
    "sample_y_train = y_train\n",
    "sample_X_test = X_test\n",
    "sample_y_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "### Integer Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:49:36.212885Z",
     "start_time": "2020-05-21T00:49:36.210779Z"
    }
   },
   "outputs": [],
   "source": [
    "#try class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:51:34.955427Z",
     "start_time": "2020-05-21T00:50:42.999908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.65      0.62     13638\n",
      "           1       0.72      0.68      0.70     18305\n",
      "\n",
      "    accuracy                           0.67     31943\n",
      "   macro avg       0.66      0.66      0.66     31943\n",
      "weighted avg       0.67      0.67      0.67     31943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.preprocessing import OrdinalEncoder\n",
    "preprocessor = ColumnTransformer([(col, ColumnEncoder('OrdinalEncoder'), col) for col in X_col])\n",
    "\n",
    "pipeline_le = Pipeline([\n",
    "    ('enc', preprocessor),\n",
    "    ('clf', LGBMClassifier()),\n",
    "     ])\n",
    " #Add param_grid for dimensionality reduction, classifier experiments\n",
    "pipeline_le.fit(sample_X_train, sample_y_train)\n",
    "pred = pipeline_le.predict(sample_X_test)\n",
    "print(classification_report(sample_y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:53:22.143979Z",
     "start_time": "2020-05-21T00:51:34.957145Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.57      0.59     13638\n",
      "           1       0.69      0.73      0.71     18305\n",
      "\n",
      "    accuracy                           0.66     31943\n",
      "   macro avg       0.65      0.65      0.65     31943\n",
      "weighted avg       0.66      0.66      0.66     31943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer([(col, ColumnEncoder('BinaryEncoder'), col) for col in X_col])\n",
    "\n",
    "pipeline_be = Pipeline([\n",
    "    ('enc', preprocessor),\n",
    "    ('clf', LGBMClassifier()),\n",
    "     ])\n",
    " #Add param_grid for dimensionality reduction, classifier experiments\n",
    "    \n",
    "pipeline_be.fit(sample_X_train, sample_y_train)\n",
    "pred = pipeline_be.predict(sample_X_test)\n",
    "print(classification_report(sample_y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:37:59.614255Z",
     "start_time": "2020-05-21T01:36:40.356815Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.69      0.64     13638\n",
      "           1       0.74      0.64      0.69     18305\n",
      "\n",
      "    accuracy                           0.67     31943\n",
      "   macro avg       0.67      0.67      0.66     31943\n",
      "weighted avg       0.68      0.67      0.67     31943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer([(col, ColumnEncoder('OneHotEncoder'), col) for col in X_col])\n",
    "\n",
    "pipeline_ohe = Pipeline([\n",
    "    ('enc', preprocessor),\n",
    "    ('clf', LGBMClassifier()),\n",
    "     ])\n",
    " #Add param_grid for dimensionality reduction, classifier experiments\n",
    "    \n",
    "pipeline_ohe.fit(sample_X_train, sample_y_train)\n",
    "pred = pipeline_ohe.predict(sample_X_test)\n",
    "print(classification_report(sample_y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashing Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:57:34.256936Z",
     "start_time": "2020-05-21T00:55:41.357735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.31      0.40     13638\n",
      "           1       0.61      0.81      0.70     18305\n",
      "\n",
      "    accuracy                           0.60     31943\n",
      "   macro avg       0.58      0.56      0.55     31943\n",
      "weighted avg       0.59      0.60      0.57     31943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ce.HashingEncoder()\n",
    "\n",
    "pipeline_fh = Pipeline([\n",
    "    ('enc', preprocessor),\n",
    "    ('clf', LGBMClassifier()),\n",
    "     ])\n",
    " #Add param_grid for dimensionality reduction, classifier experiments\n",
    "    \n",
    "pipeline_fh.fit(sample_X_train, sample_y_train)\n",
    "pred = pipeline_fh.predict(sample_X_test)\n",
    "print(classification_report(sample_y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word based: Similarity Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:59:49.657740Z",
     "start_time": "2020-05-21T00:57:34.258577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.59     13638\n",
      "           1       0.70      0.71      0.70     18305\n",
      "\n",
      "    accuracy                           0.66     31943\n",
      "   macro avg       0.65      0.65      0.65     31943\n",
      "weighted avg       0.66      0.66      0.66     31943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer([(col, ColumnEncoder('SimilarityEncoder'), col) for col in X_col])\n",
    "\n",
    "pipeline_se = Pipeline([\n",
    "    ('enc', preprocessor),\n",
    "    ('svd', TruncatedSVD(n_components=100)),\n",
    "    ('clf', LGBMClassifier()),\n",
    "     ])\n",
    " #Add param_grid for dimensionality reduction, classifier experiments\n",
    "    \n",
    "pipeline_se.fit(sample_X_train, sample_y_train)\n",
    "pred = pipeline_se.predict(sample_X_test)\n",
    "print(classification_report(sample_y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T01:17:43.571994Z",
     "start_time": "2020-05-21T01:10:53.481061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.66      0.63     13638\n",
      "           1       0.73      0.67      0.70     18305\n",
      "\n",
      "    accuracy                           0.67     31943\n",
      "   macro avg       0.66      0.67      0.66     31943\n",
      "weighted avg       0.67      0.67      0.67     31943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer([(col, ColumnEncoder('SimilarityEncoder'), col) for col in X_col])\n",
    "\n",
    "pipeline_se = Pipeline([\n",
    "    ('enc', preprocessor),\n",
    "    ('clf', LGBMClassifier()),\n",
    "     ])\n",
    " #Add param_grid for dimensionality reduction, classifier experiments\n",
    "    \n",
    "pipeline_se.fit(sample_X_train, sample_y_train)\n",
    "pred = pipeline_se.predict(sample_X_test)\n",
    "print(classification_report(sample_y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Next Steps\n",
    "\n",
    "* Tuning to see if this can make sense (number of reduced dimensions) \n",
    "* But we won't really have any way of tuning in unsupervised algorithm\n",
    "* Can we use hyperparameters tuned here in other cases as well?\n",
    "* Get more similar datasets for repeating experiments\n",
    "* Experiment with dimensionality reduction and classifiers\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
