{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Encoding\n",
    "\n",
    "* In this noebook, we experiment with different encdoers, models, and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:53:00.295255Z",
     "start_time": "2020-05-22T20:53:00.127764Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install fasttext dirty_cat category_encoders\n",
    "# !pip install lightgbm xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T20:29:10.828894Z",
     "start_time": "2020-05-26T20:29:10.824507Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from get_data import dataloader\n",
    "from column_encoder import ColumnEncoder #This is where the magic happens\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "import get_data\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "import category_encoders as ce\n",
    "#from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "# kc_train = dataloader('data/kaggle_cat_train.csv', \"kaggle_cat\")\n",
    "# kc_train.get_input_target()\n",
    "# kc_test = dataloader('data/kaggle_cat_train.csv', \"kaggle_cat\")\n",
    "# kc_test.get_input_target()\n",
    "# nominal = ['nom_'+str(i) for i in range(0,10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T20:29:15.333452Z",
     "start_time": "2020-05-26T20:29:15.240658Z"
    }
   },
   "outputs": [],
   "source": [
    "insights = dataloader('data/Insights/insights.csv', \"insights\")\n",
    "insights.get_input_target()\n",
    "X_col = insights.X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T20:29:16.659187Z",
     "start_time": "2020-05-26T20:29:16.609647Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_train_split(X, y, test_size=0.33, random_state=1):\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    sss.get_n_splits(X, y)\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = test_train_split(insights.X, insights.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T20:29:18.099123Z",
     "start_time": "2020-05-26T20:29:18.096374Z"
    }
   },
   "outputs": [],
   "source": [
    "# sample_X_train = X_train[:2000]\n",
    "# sample_y_train = y_train[:2000]\n",
    "# sample_X_test = X_test[:200]\n",
    "# sample_y_test = y_test[:200]\n",
    "\n",
    "sample_X_train = X_train\n",
    "sample_y_train = y_train\n",
    "sample_X_test = X_test\n",
    "sample_y_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "### Integer Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T00:49:36.212885Z",
     "start_time": "2020-05-21T00:49:36.210779Z"
    }
   },
   "outputs": [],
   "source": [
    "#try class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T20:34:32.854987Z",
     "start_time": "2020-05-26T20:34:18.831259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.77      0.66     13638\n",
      "           1       0.77      0.57      0.65     18305\n",
      "\n",
      "    accuracy                           0.65     31943\n",
      "   macro avg       0.67      0.67      0.65     31943\n",
      "weighted avg       0.69      0.65      0.65     31943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.preprocessing import OrdinalEncoder\n",
    "preprocessor = ColumnTransformer([(col, ColumnEncoder('OrdinalEncoder'), col) for col in X_col])\n",
    "\n",
    "pipeline_le = Pipeline([\n",
    "    ('enc', preprocessor),\n",
    "    ('clf', LGBMClassifier(is_unbalance='True')),\n",
    "     ])\n",
    " #Add param_grid for dimensionality reduction, classifier experiments\n",
    "pipeline_le.fit(sample_X_train, sample_y_train)\n",
    "pred = pipeline_le.predict(sample_X_test)\n",
    "print(classification_report(sample_y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T20:35:50.950489Z",
     "start_time": "2020-05-26T20:34:48.262196Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.77      0.66     13638\n",
      "           1       0.77      0.57      0.65     18305\n",
      "\n",
      "    accuracy                           0.66     31943\n",
      "   macro avg       0.67      0.67      0.66     31943\n",
      "weighted avg       0.69      0.66      0.66     31943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer([(col, ColumnEncoder('BinaryEncoder'), col) for col in X_col])\n",
    "\n",
    "pipeline_be = Pipeline([\n",
    "    ('enc', preprocessor),\n",
    "    ('clf', LGBMClassifier(is_unbalance='True')),\n",
    "     ])\n",
    " #Add param_grid for dimensionality reduction, classifier experiments\n",
    "    \n",
    "pipeline_be.fit(sample_X_train, sample_y_train)\n",
    "pred = pipeline_be.predict(sample_X_test)\n",
    "print(classification_report(sample_y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T20:36:08.048309Z",
     "start_time": "2020-05-26T20:35:50.952874Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.79      0.66     13638\n",
      "           1       0.78      0.56      0.65     18305\n",
      "\n",
      "    accuracy                           0.66     31943\n",
      "   macro avg       0.67      0.67      0.66     31943\n",
      "weighted avg       0.69      0.66      0.65     31943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer([(col, ColumnEncoder('OneHotEncoder'), col) for col in X_col])\n",
    "\n",
    "pipeline_ohe = Pipeline([\n",
    "    ('enc', preprocessor),\n",
    "    ('clf', LGBMClassifier(is_unbalance='True')),\n",
    "     ])\n",
    " #Add param_grid for dimensionality reduction, classifier experiments\n",
    "    \n",
    "pipeline_ohe.fit(sample_X_train, sample_y_train)\n",
    "pred = pipeline_ohe.predict(sample_X_test)\n",
    "print(classification_report(sample_y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashing Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T20:37:06.250742Z",
     "start_time": "2020-05-26T20:36:08.050038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.81      0.62     13638\n",
      "           1       0.74      0.41      0.53     18305\n",
      "\n",
      "    accuracy                           0.58     31943\n",
      "   macro avg       0.62      0.61      0.58     31943\n",
      "weighted avg       0.64      0.58      0.57     31943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ce.HashingEncoder()\n",
    "\n",
    "pipeline_fh = Pipeline([\n",
    "    ('enc', preprocessor),\n",
    "    ('clf', LGBMClassifier(is_unbalance='True')),\n",
    "     ])\n",
    " #Add param_grid for dimensionality reduction, classifier experiments\n",
    "    \n",
    "pipeline_fh.fit(sample_X_train, sample_y_train)\n",
    "pred = pipeline_fh.predict(sample_X_test)\n",
    "print(classification_report(sample_y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word based: Similarity Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T20:47:55.101289Z",
     "start_time": "2020-05-26T20:47:55.091856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenuineIntel                    50341\n",
       "Intel                            6483\n",
       "Intel(R) Corporation             4214\n",
       "Red Hat                          3046\n",
       "AuthenticAMD                      509\n",
       "Bochs                             137\n",
       "AMD                                79\n",
       "QEMU                               39\n",
       "Intel Corporation                   2\n",
       "nan                                 1\n",
       "Advanced Micro Devices, Inc.        1\n",
       "Name: pmanufacturer, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_X_train['pmanufacturer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T20:37:43.958602Z",
     "start_time": "2020-05-26T20:37:06.252399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.73      0.65     13638\n",
      "           1       0.75      0.60      0.67     18305\n",
      "\n",
      "    accuracy                           0.66     31943\n",
      "   macro avg       0.66      0.67      0.66     31943\n",
      "weighted avg       0.68      0.66      0.66     31943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer([(col, ColumnEncoder('SimilarityEncoder'), col) for col in X_col])\n",
    "\n",
    "pipeline_se = Pipeline([\n",
    "    ('enc', preprocessor),\n",
    "    ('svd', TruncatedSVD(n_components=100)),\n",
    "    ('clf', LGBMClassifier(is_unbalance='True')),\n",
    "     ])\n",
    " #Add param_grid for dimensionality reduction, classifier experiments\n",
    "    \n",
    "pipeline_se.fit(sample_X_train, sample_y_train)\n",
    "pred = pipeline_se.predict(sample_X_test)\n",
    "print(classification_report(sample_y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T20:38:56.362925Z",
     "start_time": "2020-05-26T20:37:43.960350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.75      0.66     13638\n",
      "           1       0.76      0.59      0.67     18305\n",
      "\n",
      "    accuracy                           0.66     31943\n",
      "   macro avg       0.67      0.67      0.66     31943\n",
      "weighted avg       0.69      0.66      0.66     31943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer([(col, ColumnEncoder('SimilarityEncoder'), col) for col in X_col])\n",
    "\n",
    "pipeline_se = Pipeline([\n",
    "    ('enc', preprocessor),\n",
    "    ('clf', LGBMClassifier(is_unbalance='True')),\n",
    "     ])\n",
    " #Add param_grid for dimensionality reduction, classifier experiments\n",
    "    \n",
    "pipeline_se.fit(sample_X_train, sample_y_train)\n",
    "pred = pipeline_se.predict(sample_X_test)\n",
    "print(classification_report(sample_y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Next Steps\n",
    "\n",
    "* Tuning to see if this can make sense (number of reduced dimensions) \n",
    "* But we won't really have any way of tuning in unsupervised algorithm\n",
    "* Can we use hyperparameters tuned here in other cases as well?\n",
    "* Get more similar datasets for repeating experiments\n",
    "* Experiment with dimensionality reduction and classifiers\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
